[
  {
    "experiment": "clear_global_total_kfold",
    "parameter": "64, 256, 512, 0.3",
    "fold_accuracies": 0.8457948121050881,
    "fold_accuracies_list": [
      0.8490322580645161,
      0.8595360824742269,
      0.8348387096774194,
      0.8479381443298969,
      0.8376288659793815
    ],
    "log": [
      "              precision    recall  f1-score   support\n\n           0     0.9197    0.7683    0.8372       164\n           1     0.7778    0.8630    0.8182       146\n           2     0.9012    0.6759    0.7725       108\n           3     0.8313    0.9583    0.8903        72\n           4     0.8652    0.9390    0.9006        82\n           5     0.7500    0.9000    0.8182        30\n           6     0.8556    0.9249    0.8889       173\n\n    accuracy                         0.8490       775\n   macro avg     0.8430    0.8613    0.8466       775\nweighted avg     0.8555    0.8490    0.8470       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.7871    0.8472    0.8161       144\n           1     0.8430    0.8788    0.8605       165\n           2     0.8636    0.7677    0.8128        99\n           3     0.7778    0.8305    0.8033        59\n           4     0.9625    0.8105    0.8800        95\n           5     0.7500    0.7241    0.7368        29\n           6     0.9316    0.9568    0.9440       185\n\n    accuracy                         0.8595       776\n   macro avg     0.8451    0.8308    0.8362       776\nweighted avg     0.8626    0.8595    0.8595       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8514    0.7826    0.8155       161\n           1     0.8452    0.8256    0.8353       172\n           2     0.6887    0.8202    0.7487        89\n           3     0.8070    0.8364    0.8214        55\n           4     0.8421    0.8602    0.8511        93\n           5     0.7419    0.6970    0.7188        33\n           6     0.9235    0.9128    0.9181       172\n\n    accuracy                         0.8348       775\n   macro avg     0.8143    0.8193    0.8156       775\nweighted avg     0.8384    0.8348    0.8356       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.8061    0.8471    0.8261       157\n           1     0.8228    0.7831    0.8025       166\n           2     0.8133    0.7262    0.7673        84\n           3     0.9273    0.8644    0.8947        59\n           4     0.9247    0.8687    0.8958        99\n           5     0.7778    0.8485    0.8116        33\n           6     0.8711    0.9494    0.9086       178\n\n    accuracy                         0.8479       776\n   macro avg     0.8490    0.8411    0.8438       776\nweighted avg     0.8485    0.8479    0.8471       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8417    0.7452    0.7905       157\n           1     0.7735    0.9272    0.8434       151\n           2     0.7250    0.7733    0.7484        75\n           3     0.8868    0.7833    0.8319        60\n           4     0.9740    0.7732    0.8621        97\n           5     0.9524    0.6452    0.7692        31\n           6     0.8578    0.9415    0.8977       205\n\n    accuracy                         0.8376       776\n   macro avg     0.8587    0.7984    0.8204       776\nweighted avg     0.8458    0.8376    0.8363       776\n"
    ]
  },
  {
    "experiment": "clear_global_total_kfold",
    "parameter": "64, 128, 32, 0.3",
    "fold_accuracies": 0.8006684403059527,
    "fold_accuracies_list": [
      0.8129032258064516,
      0.7989690721649485,
      0.7806451612903226,
      0.7835051546391752,
      0.8273195876288659
    ],
    "log": [
      "              precision    recall  f1-score   support\n\n           0     0.7733    0.7682    0.7708       151\n           1     0.8092    0.7834    0.7961       157\n           2     0.7765    0.7586    0.7674        87\n           3     0.8036    0.7759    0.7895        58\n           4     0.8571    0.8348    0.8458       115\n           5     0.8462    0.8148    0.8302        27\n           6     0.8351    0.9000    0.8663       180\n\n    accuracy                         0.8129       775\n   macro avg     0.8144    0.8051    0.8094       775\nweighted avg     0.8125    0.8129    0.8123       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.8045    0.8000    0.8022       180\n           1     0.7949    0.7949    0.7949       156\n           2     0.6837    0.7363    0.7090        91\n           3     0.8065    0.7246    0.7634        69\n           4     0.8481    0.8272    0.8375        81\n           5     0.8571    0.6207    0.7200        29\n           6     0.8287    0.8824    0.8547       170\n\n    accuracy                         0.7990       776\n   macro avg     0.8033    0.7694    0.7831       776\nweighted avg     0.8004    0.7990    0.7985       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.7000    0.7447    0.7216       141\n           1     0.8092    0.7821    0.7955       179\n           2     0.7059    0.6742    0.6897        89\n           3     0.7419    0.7419    0.7419        62\n           4     0.8095    0.8608    0.8344        79\n           5     0.6667    0.6667    0.6667        27\n           6     0.8660    0.8485    0.8571       198\n\n    accuracy                         0.7806       775\n   macro avg     0.7570    0.7598    0.7581       775\nweighted avg     0.7817    0.7806    0.7808       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.7664    0.7000    0.7317       150\n           1     0.7764    0.7669    0.7716       163\n           2     0.6780    0.7921    0.7306       101\n           3     0.8947    0.7727    0.8293        66\n           4     0.8734    0.7753    0.8214        89\n           5     0.8000    0.6667    0.7273        36\n           6     0.7938    0.9006    0.8438       171\n\n    accuracy                         0.7835       776\n   macro avg     0.7975    0.7677    0.7794       776\nweighted avg     0.7878    0.7835    0.7830       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8227    0.7205    0.7682       161\n           1     0.8065    0.8621    0.8333       145\n           2     0.7204    0.7701    0.7444        87\n           3     0.7593    0.8200    0.7885        50\n           4     0.8571    0.8824    0.8696       102\n           5     0.9655    0.7568    0.8485        37\n           6     0.8794    0.9021    0.8906       194\n\n    accuracy                         0.8273       776\n   macro avg     0.8301    0.8163    0.8204       776\nweighted avg     0.8296    0.8273    0.8268       776\n"
    ]
  },
  {
    "experiment": "clear_global_total_kfold",
    "parameter": "64, 128, 64, 0.3",
    "fold_accuracies": 0.826975058197539,
    "fold_accuracies_list": [
      0.8270967741935484,
      0.7860824742268041,
      0.8361290322580646,
      0.8492268041237113,
      0.836340206185567
    ],
    "log": [
      "              precision    recall  f1-score   support\n\n           0     0.8070    0.7977    0.8023       173\n           1     0.8323    0.8323    0.8323       161\n           2     0.7283    0.7614    0.7444        88\n           3     0.8393    0.7833    0.8103        60\n           4     0.7835    0.9048    0.8398        84\n           5     0.8387    0.8667    0.8525        30\n           6     0.9162    0.8547    0.8844       179\n\n    accuracy                         0.8271       775\n   macro avg     0.8207    0.8287    0.8237       775\nweighted avg     0.8297    0.8271    0.8276       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.6933    0.7386    0.7152       153\n           1     0.7619    0.8205    0.7901       156\n           2     0.7742    0.7059    0.7385       102\n           3     0.8333    0.7143    0.7692        56\n           4     0.8000    0.8400    0.8195       100\n           5     0.7241    0.7241    0.7241        29\n           6     0.8941    0.8444    0.8686       180\n\n    accuracy                         0.7861       776\n   macro avg     0.7830    0.7697    0.7750       776\nweighted avg     0.7893    0.7861    0.7866       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.7435    0.8554    0.7955       166\n           1     0.8526    0.7688    0.8085       173\n           2     0.7727    0.8293    0.8000        82\n           3     0.9500    0.8636    0.9048        66\n           4     0.9067    0.8831    0.8947        77\n           5     0.7667    0.7931    0.7797        29\n           6     0.8971    0.8626    0.8796       182\n\n    accuracy                         0.8361       775\n   macro avg     0.8413    0.8366    0.8375       775\nweighted avg     0.8417    0.8361    0.8372       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.7588    0.8836    0.8165       146\n           1     0.8428    0.8590    0.8508       156\n           2     0.8642    0.7447    0.8000        94\n           3     0.8507    0.7917    0.8201        72\n           4     0.9048    0.8261    0.8636        92\n           5     0.7931    0.9200    0.8519        25\n           6     0.9140    0.8901    0.9019       191\n\n    accuracy                         0.8492       776\n   macro avg     0.8469    0.8450    0.8435       776\nweighted avg     0.8536    0.8492    0.8495       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.7677    0.8207    0.7933       145\n           1     0.8067    0.7857    0.7961       154\n           2     0.7931    0.7753    0.7841        89\n           3     0.8364    0.9020    0.8679        51\n           4     0.8942    0.8230    0.8571       113\n           5     0.8889    0.9302    0.9091        43\n           6     0.8944    0.8895    0.8920       181\n\n    accuracy                         0.8363       776\n   macro avg     0.8402    0.8466    0.8428       776\nweighted avg     0.8376    0.8363    0.8364       776\n"
    ]
  },
  {
    "experiment": "clear_global_total_kfold",
    "parameter": "64, 128, 128, 0.3",
    "fold_accuracies": 0.8460535417359495,
    "fold_accuracies_list": [
      0.8309677419354838,
      0.8556701030927835,
      0.8567741935483871,
      0.8402061855670103,
      0.8466494845360825
    ],
    "log": [
      "              precision    recall  f1-score   support\n\n           0     0.7383    0.8271    0.7801       133\n           1     0.8207    0.8041    0.8123       148\n           2     0.8632    0.8367    0.8497        98\n           3     0.8772    0.7246    0.7937        69\n           4     0.8384    0.8646    0.8513        96\n           5     0.7857    0.7097    0.7458        31\n           6     0.8812    0.8900    0.8856       200\n\n    accuracy                         0.8310       775\n   macro avg     0.8292    0.8081    0.8169       775\nweighted avg     0.8333    0.8310    0.8309       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.8012    0.8636    0.8313       154\n           1     0.8851    0.8291    0.8562       158\n           2     0.8046    0.7368    0.7692        95\n           3     0.8182    0.8571    0.8372        63\n           4     0.9091    0.9000    0.9045       100\n           5     0.9333    0.6667    0.7778        21\n           6     0.8821    0.9297    0.9053       185\n\n    accuracy                         0.8557       776\n   macro avg     0.8619    0.8262    0.8402       776\nweighted avg     0.8568    0.8557    0.8549       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8014    0.8182    0.8097       143\n           1     0.8436    0.8483    0.8459       178\n           2     0.8351    0.8526    0.8438        95\n           3     0.7705    0.8545    0.8103        55\n           4     0.8902    0.9012    0.8957        81\n           5     0.8667    0.7647    0.8125        34\n           6     0.9389    0.8942    0.9160       189\n\n    accuracy                         0.8568       775\n   macro avg     0.8495    0.8477    0.8477       775\nweighted avg     0.8587    0.8568    0.8573       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.8444    0.8261    0.8352       184\n           1     0.7950    0.8258    0.8101       155\n           2     0.7468    0.7468    0.7468        79\n           3     0.8824    0.8824    0.8824        68\n           4     0.9011    0.8367    0.8677        98\n           5     0.8077    0.7778    0.7925        27\n           6     0.8772    0.9091    0.8929       165\n\n    accuracy                         0.8402       776\n   macro avg     0.8364    0.8292    0.8325       776\nweighted avg     0.8408    0.8402    0.8402       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8098    0.7811    0.7952       169\n           1     0.8187    0.8696    0.8434       161\n           2     0.8125    0.7386    0.7738        88\n           3     0.8269    0.8600    0.8431        50\n           4     0.8817    0.9011    0.8913        91\n           5     0.9474    0.8372    0.8889        43\n           6     0.8883    0.9138    0.9008       174\n\n    accuracy                         0.8466       776\n   macro avg     0.8550    0.8431    0.8481       776\nweighted avg     0.8467    0.8466    0.8460       776\n"
    ]
  },
  {
    "experiment": "clear_global_total_kfold",
    "parameter": "64, 128, 256, 0.3",
    "fold_accuracies": 0.8496637845028268,
    "fold_accuracies_list": [
      0.8167741935483871,
      0.8608247422680413,
      0.8787096774193548,
      0.8311855670103093,
      0.8608247422680413
    ],
    "log": [
      "              precision    recall  f1-score   support\n\n           0     0.7950    0.7711    0.7829       166\n           1     0.7765    0.8148    0.7952       162\n           2     0.7692    0.7778    0.7735        90\n           3     0.7966    0.7833    0.7899        60\n           4     0.7912    0.8276    0.8090        87\n           5     0.9062    0.8529    0.8788        34\n           6     0.9064    0.8807    0.8934       176\n\n    accuracy                         0.8168       775\n   macro avg     0.8202    0.8155    0.8175       775\nweighted avg     0.8180    0.8168    0.8171       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.8052    0.8435    0.8239       147\n           1     0.7941    0.8710    0.8308       155\n           2     0.8696    0.7692    0.8163       104\n           3     0.9600    0.7742    0.8571        62\n           4     0.9239    0.8673    0.8947        98\n           5     0.9167    0.8800    0.8980        25\n           6     0.8969    0.9405    0.9182       185\n\n    accuracy                         0.8608       776\n   macro avg     0.8809    0.8494    0.8627       776\nweighted avg     0.8644    0.8608    0.8607       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8528    0.8854    0.8688       157\n           1     0.8896    0.8616    0.8754       159\n           2     0.8427    0.8523    0.8475        88\n           3     0.9032    0.8485    0.8750        66\n           4     0.9222    0.8737    0.8973        95\n           5     0.8438    0.7714    0.8060        35\n           6     0.8865    0.9371    0.9111       175\n\n    accuracy                         0.8787       775\n   macro avg     0.8773    0.8614    0.8687       775\nweighted avg     0.8792    0.8787    0.8785       775\n",
      "              precision    recall  f1-score   support\n\n           0     0.7951    0.6736    0.7293       144\n           1     0.7459    0.8734    0.8047       158\n           2     0.8488    0.8022    0.8249        91\n           3     0.9375    0.8491    0.8911        53\n           4     0.9368    0.8725    0.9036       102\n           5     0.8400    0.7000    0.7636        30\n           6     0.8465    0.9192    0.8814       198\n\n    accuracy                         0.8312       776\n   macro avg     0.8501    0.8129    0.8284       776\nweighted avg     0.8346    0.8312    0.8299       776\n",
      "              precision    recall  f1-score   support\n\n           0     0.8563    0.8462    0.8512       169\n           1     0.8494    0.8494    0.8494       166\n           2     0.8312    0.7805    0.8050        82\n           3     0.8548    0.8281    0.8413        64\n           4     0.8333    0.8929    0.8621        84\n           5     1.0000    0.8750    0.9333        32\n           6     0.8817    0.9162    0.8986       179\n\n    accuracy                         0.8608       776\n   macro avg     0.8724    0.8555    0.8630       776\nweighted avg     0.8613    0.8608    0.8606       776\n"
    ]
  }
]